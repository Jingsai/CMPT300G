{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_Step4_ModelTesting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOHkffMms2ee3wW32b4gn+u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jingsai/CMPT300G/blob/master/project/Project_Step4_ModelTesting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code"
      ],
      "metadata": {
        "id": "cX3n4HxMPczf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1 - download testing data and labels\n",
        "\n",
        "https://cs.westminstercollege.edu/~jingsai/courses/CMPT300G/pelican/final_test_pelican.zip\n",
        "\n",
        "**DO NOT** label any testing data downloaded this time since all the labels are already provided."
      ],
      "metadata": {
        "id": "CP2BKMAxLsyi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2 - train your model using different hyperparamters\n",
        "\n",
        "Train your model various times by adjusting hyperparameters and other techniques. The goal is to **achieve the highest mAP in all** on the **final testing data**. \n",
        "\n",
        "You need to **change your ymal file** to replace the val row as the path to the final testing pelican. \n",
        "\n",
        "You may try changing:\n",
        "\n",
        "- different augmentation like fliping, hsv, light, etc. \n",
        "- img size in **training and testing** like 640, 980, 1080.\n",
        "- batch size like 10, 15, 20, 25, 32.\n",
        "- number of epochs like 20, 30, 50, 100.\n",
        "- different weight and model like yolov5s, yolov5m, yolov5l. \n",
        "\n",
        "<img width=700 src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/model_comparison.png\">"
      ],
      "metadata": {
        "id": "lwf4njJmPoxw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3 - evaluation the model \n",
        "\n",
        "You can evaluate your model using the weights you just trained or loading pre-trained weight you saved in your google drive. \n",
        "\n",
        "The best overall mAP@.5 I got on my machine is around 82.5%. "
      ],
      "metadata": {
        "id": "V2rOUTYYSVla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python val.py --weights '/content/drive/MyDrive/pelican/weights/original_data_best.pt' --data '/content/drive/MyDrive/pelican/test.yaml' --img 960"
      ],
      "metadata": {
        "id": "IDSNj7ycKSBO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "240838b5-b186-4c83-ef15-7e351dac2101"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/drive/MyDrive/pelican/test.yaml, weights=['/content/drive/MyDrive/pelican/weights/original_data_best.pt'], batch_size=32, imgsz=960, conf_thres=0.001, iou_thres=0.6, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
            "YOLOv5 ðŸš€ v6.1-242-ga80dd66 Python-3.7.13 torch-1.11.0+cu113 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 290 layers, 20861016 parameters, 0 gradients, 48.0 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/pelican/final_test_pelican/labels' images and labels...121 found, 1 missing, 0 empty, 0 corrupt: 100% 122/122 [00:28<00:00,  4.21it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/pelican/final_test_pelican/labels.cache\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [02:52<00:00, 43.20s/it]\n",
            "                 all        122        950      0.788      0.793      0.825      0.539\n",
            "              flying        122         68      0.733      0.691      0.725      0.419\n",
            "             no_beak        122        633      0.751      0.807      0.828      0.503\n",
            "                beak        122        249       0.88       0.88      0.922      0.695\n",
            "Speed: 9.8ms pre-process, 1354.3ms inference, 1.4ms NMS per image at shape (32, 3, 960, 960)\n",
            "Results saved to \u001b[1mruns/val/exp3\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4\n",
        "\n",
        "Write your answers to following questions:\n",
        "\n",
        "1. What the best mAP@.5 and mAP@.5:.95 in all data you got on the **final** testing data?\n",
        "\n",
        "2. What are the hyperparameters you used in the best model, such as --img, --batch, --epochs, --weights? \n",
        "\n",
        "3. Are you satified with the performance of your best model? If not, please explain what else will you do to coniture improving your model? "
      ],
      "metadata": {
        "id": "uKErZZvRPdBd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submission\n",
        "\n",
        "Submit your project notebook .ipynb file with best performance of mAP to Canvas by Friday 6/3. "
      ],
      "metadata": {
        "id": "QiPMTBwC6Tvx"
      }
    }
  ]
}